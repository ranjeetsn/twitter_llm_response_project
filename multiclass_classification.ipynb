{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import snowballstemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import nltk\n",
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in ./.venv/lib/python3.11/site-packages (2.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting snowballstemmer\n",
      "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: snowballstemmer\n",
      "Successfully installed snowballstemmer-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install snowballstemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.47.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (157 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading Pillow-10.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.8.2-cp311-cp311-macosx_11_0_arm64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.0-cp311-cp311-macosx_11_0_arm64.whl (243 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.4/243.4 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.47.0-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp311-cp311-macosx_11_0_arm64.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Pillow-10.1.0-cp311-cp311-macosx_11_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.47.0 kiwisolver-1.4.5 matplotlib-3.8.2 pillow-10.1.0 pyparsing-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.venv/lib/python3.11/site-packages (from seaborn) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.11/site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in ./.venv/lib/python3.11/site-packages (from seaborn) (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "Using cached seaborn-0.13.0-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>token</th>\n",
       "      <th>topic_no</th>\n",
       "      <th>topic_prob</th>\n",
       "      <th>topic_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>['aggressive', 'blast', 'obnoxious', 'entertai...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.221675</td>\n",
       "      <td>Reschedule and Refund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.214476</td>\n",
       "      <td>Reschedule and Refund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>570300767074181121</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:33 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>['seat', 'play', 'fly']</td>\n",
       "      <td>4</td>\n",
       "      <td>0.227286</td>\n",
       "      <td>Phone and Online Booking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>570282469121007616</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Late Flight</td>\n",
       "      <td>0.3684</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>smartwatermelon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica SFO-PDX schedule is still MIA.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 10:01:50 -0800</td>\n",
       "      <td>palo alto, ca</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>['sfopdx', 'schedule']</td>\n",
       "      <td>3</td>\n",
       "      <td>0.259870</td>\n",
       "      <td>Reschedule and Refund</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>570276917301137409</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>heatherovieda</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last we...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 09:39:46 -0800</td>\n",
       "      <td>this place called NYC</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>['fully', 'large', 'gentleman']</td>\n",
       "      <td>3</td>\n",
       "      <td>0.193757</td>\n",
       "      <td>Reschedule and Refund</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            tweet_id airline_sentiment  \\\n",
       "0           0  570301031407624196          negative   \n",
       "1           1  570300817074462722          negative   \n",
       "2           2  570300767074181121          negative   \n",
       "3           3  570282469121007616          negative   \n",
       "4           4  570276917301137409          negative   \n",
       "\n",
       "   airline_sentiment_confidence negativereason  negativereason_confidence  \\\n",
       "0                        1.0000     Bad Flight                     0.7033   \n",
       "1                        1.0000     Can't Tell                     1.0000   \n",
       "2                        1.0000     Can't Tell                     0.6842   \n",
       "3                        0.6842    Late Flight                     0.3684   \n",
       "4                        1.0000     Bad Flight                     1.0000   \n",
       "\n",
       "          airline airline_sentiment_gold             name negativereason_gold  \\\n",
       "0  Virgin America                    NaN         jnardino                 NaN   \n",
       "1  Virgin America                    NaN         jnardino                 NaN   \n",
       "2  Virgin America                    NaN         jnardino                 NaN   \n",
       "3  Virgin America                    NaN  smartwatermelon                 NaN   \n",
       "4  Virgin America                    NaN    heatherovieda                 NaN   \n",
       "\n",
       "   retweet_count                                               text  \\\n",
       "0              0  @VirginAmerica it's really aggressive to blast...   \n",
       "1              0  @VirginAmerica and it's a really big bad thing...   \n",
       "2              0  @VirginAmerica seriously would pay $30 a fligh...   \n",
       "3              0      @VirginAmerica SFO-PDX schedule is still MIA.   \n",
       "4              0  @VirginAmerica  I flew from NYC to SFO last we...   \n",
       "\n",
       "  tweet_coord              tweet_created         tweet_location  \\\n",
       "0         NaN  2015-02-24 11:15:36 -0800                    NaN   \n",
       "1         NaN  2015-02-24 11:14:45 -0800                    NaN   \n",
       "2         NaN  2015-02-24 11:14:33 -0800                    NaN   \n",
       "3         NaN  2015-02-24 10:01:50 -0800          palo alto, ca   \n",
       "4         NaN  2015-02-24 09:39:46 -0800  this place called NYC   \n",
       "\n",
       "                user_timezone  \\\n",
       "0  Pacific Time (US & Canada)   \n",
       "1  Pacific Time (US & Canada)   \n",
       "2  Pacific Time (US & Canada)   \n",
       "3  Pacific Time (US & Canada)   \n",
       "4  Eastern Time (US & Canada)   \n",
       "\n",
       "                                               token  topic_no  topic_prob  \\\n",
       "0  ['aggressive', 'blast', 'obnoxious', 'entertai...         3    0.221675   \n",
       "1                                                 []         3    0.214476   \n",
       "2                            ['seat', 'play', 'fly']         4    0.227286   \n",
       "3                             ['sfopdx', 'schedule']         3    0.259870   \n",
       "4                    ['fully', 'large', 'gentleman']         3    0.193757   \n",
       "\n",
       "                 topic_desc  \n",
       "0     Reschedule and Refund  \n",
       "1     Reschedule and Refund  \n",
       "2  Phone and Online Booking  \n",
       "3     Reschedule and Refund  \n",
       "4     Reschedule and Refund  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/labelled_airline_tweet.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_desc</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reschedule and Refund</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reschedule and Refund</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phone and Online Booking</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reschedule and Refund</td>\n",
       "      <td>@VirginAmerica SFO-PDX schedule is still MIA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reschedule and Refund</td>\n",
       "      <td>@VirginAmerica  I flew from NYC to SFO last we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 topic_desc                                               text\n",
       "0     Reschedule and Refund  @VirginAmerica it's really aggressive to blast...\n",
       "1     Reschedule and Refund  @VirginAmerica and it's a really big bad thing...\n",
       "2  Phone and Online Booking  @VirginAmerica seriously would pay $30 a fligh...\n",
       "3     Reschedule and Refund      @VirginAmerica SFO-PDX schedule is still MIA.\n",
       "4     Reschedule and Refund  @VirginAmerica  I flew from NYC to SFO last we..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[['topic_desc', 'text']].copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_desc</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>Baggage Issue</td>\n",
       "      <td>@united - terrible experience on UA415 on 17th. 1st exit row in economy has zero legroom. Have same row booked for return but can't change.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6032</th>\n",
       "      <td>Baggage Issue</td>\n",
       "      <td>@USAirways can you please train your mechanics? Teach them to bring the tools to fix the plane with them and not leave them in the hanger.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Reschedule and Refund</td>\n",
       "      <td>@united It's still a valid flight. Just seems strange to delay for Late Flight inbound crew,  7 hours from now, when the plane is already here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7014</th>\n",
       "      <td>Reschedule and Refund</td>\n",
       "      <td>@USAirways hey let flight 1874get to the gate  hours Late Flight and no fate with dozens of kids on board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>Reschedule and Refund</td>\n",
       "      <td>@united too big to properly manage flight times. There is such a thing as being on time. Or at least prepared with a gate when we land!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 topic_desc  \\\n",
       "1803  Baggage Issue           \n",
       "6032  Baggage Issue           \n",
       "328   Reschedule and Refund   \n",
       "7014  Reschedule and Refund   \n",
       "2090  Reschedule and Refund   \n",
       "\n",
       "                                                                                                                                                 text  \n",
       "1803  @united - terrible experience on UA415 on 17th. 1st exit row in economy has zero legroom. Have same row booked for return but can't change.      \n",
       "6032  @USAirways can you please train your mechanics? Teach them to bring the tools to fix the plane with them and not leave them in the hanger.       \n",
       "328   @united It's still a valid flight. Just seems strange to delay for Late Flight inbound crew,  7 hours from now, when the plane is already here.  \n",
       "7014  @USAirways hey let flight 1874get to the gate  hours Late Flight and no fate with dozens of kids on board                                        \n",
       "2090  @united too big to properly manage flight times. There is such a thing as being on time. Or at least prepared with a gate when we land!          "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 1)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic_desc\n",
       "Reschedule and Refund         6512\n",
       "Baggage Issue                 1513\n",
       "Phone and Online Booking      421 \n",
       "Extra Charges                 268 \n",
       "Delay and Customer Service    223 \n",
       "Seating Preferences           153 \n",
       "Reservation Issue             78  \n",
       "Customer Experience           10  \n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['topic_desc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica hi! I just bked a cool birthday trip with you, but i can't add my elevate no. cause i entered my middle name during Flight Booking Problems 😢\n",
      "Greivance type: Reservation Issue\n"
     ]
    }
   ],
   "source": [
    "def print_plot(index):\n",
    "    example = df[df.index == index][['text','topic_desc']].values[0]\n",
    "    if len(example) > 0 and example is not None:\n",
    "        print(example[0])\n",
    "        print('Greivance type:', example[1])\n",
    "print_plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Preprocessing\n",
    "import re\n",
    "\n",
    "def clean_text(txt):\n",
    "    \n",
    "    \"\"\"\n",
    "    removing all hashtags , punctuations, stop_words  and links, also stemming words \n",
    "    \"\"\"\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"(?<=\\w)nt\", \"not\",txt) #change don't to do not cna't to cannot \n",
    "    txt = re.sub(r\"(@\\S+)\", \"\", txt)  # remove hashtags\n",
    "    txt = re.sub(r'\\W', ' ', str(txt)) # remove all special characters including apastrophie \n",
    "    txt = txt.translate(str.maketrans('', '', string.punctuation)) # remove punctuations \n",
    "    txt = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', txt)   # remove all single characters (it's -> it s then we need to remove s)\n",
    "    txt = re.sub(r'\\s+', ' ', txt, flags=re.I) # Substituting multiple spaces with single space\n",
    "    txt = re.sub(r\"(http\\S+|http)\", \"\", txt) # remove links \n",
    "    txt = ' '.join([PorterStemmer().stem(word=word) for word in txt.split(\" \") if word not in stopwords.words('english') ]) # stem & remove stop words\n",
    "    txt = ''.join([i for i in txt if not i.isdigit()]).strip() # remove digits ()\n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text :  @VirginAmerica why are your first fares in May over three times more than other carriers when all seats are available to select???\n",
      "Processed Text :  first fare may three time carrier seat avail select\n"
     ]
    }
   ],
   "source": [
    "print('Original Text : ',data['text'][5])  \n",
    "print('Processed Text : ',clean_text(data['text'][5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['realli aggress blast obnoxi enotertainmenot guest face amp littl recours',\n",
       "       'realli big bad thing',\n",
       "       'serious would pay  flight seat play realli bad thing fli va', ...,\n",
       "       'right cue delay',\n",
       "       'leav  minut late flight warn commun unotil  minut late flight call shitti custom svc',\n",
       "       'money chang flight answer phone suggest make commitmenot'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(clean_text)\n",
    "data['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11306 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 50000\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: 250\n"
     ]
    }
   ],
   "source": [
    "# Word Embedding\n",
    "X = tokenizer.texts_to_sequences(df['text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (9178, 8)\n"
     ]
    }
   ],
   "source": [
    "#Converting categorical labels to numbers.\n",
    "Y = pd.get_dummies(df['topic_desc']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8260, 250) (8260, 8)\n",
      "(918, 250) (918, 8)\n"
     ]
    }
   ],
   "source": [
    "#Train-Test Split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 15:06:18.278236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117/117 [==============================] - 18723s 160s/step - loss: 1.0608 - accuracy: 0.7031 - val_loss: 0.9765 - val_accuracy: 0.7119\n",
      "Epoch 2/10\n",
      "117/117 [==============================] - 18746s 160s/step - loss: 0.8400 - accuracy: 0.7355 - val_loss: 0.8986 - val_accuracy: 0.7143\n",
      "Epoch 3/10\n",
      "117/117 [==============================] - 17678s 151s/step - loss: 0.6003 - accuracy: 0.8154 - val_loss: 0.8264 - val_accuracy: 0.7470\n",
      "Epoch 4/10\n",
      "117/117 [==============================] - 16335s 140s/step - loss: 0.4331 - accuracy: 0.8678 - val_loss: 0.7483 - val_accuracy: 0.7797\n",
      "Epoch 5/10\n",
      "117/117 [==============================] - 18361s 157s/step - loss: 0.3300 - accuracy: 0.8953 - val_loss: 0.7689 - val_accuracy: 0.7615\n",
      "Epoch 6/10\n",
      "117/117 [==============================] - 17785s 152s/step - loss: 0.2230 - accuracy: 0.9337 - val_loss: 0.8071 - val_accuracy: 0.7663\n",
      "Epoch 7/10\n",
      "117/117 [==============================] - 22547s 193s/step - loss: 0.1579 - accuracy: 0.9516 - val_loss: 0.8571 - val_accuracy: 0.7591\n",
      "Epoch 8/10\n",
      "117/117 [==============================] - 18291s 156s/step - loss: 0.1164 - accuracy: 0.9664 - val_loss: 0.9108 - val_accuracy: 0.7542\n",
      "Epoch 9/10\n",
      "117/117 [==============================] - 16580s 142s/step - loss: 0.0806 - accuracy: 0.9786 - val_loss: 0.9206 - val_accuracy: 0.7712\n",
      "Epoch 10/10\n",
      "117/117 [==============================] - 38547s 331s/step - loss: 0.0554 - accuracy: 0.9839 - val_loss: 0.9194 - val_accuracy: 0.7797\n"
     ]
    }
   ],
   "source": [
    "# Model Structuring\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, verbose=1, mode='auto')\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 250, 100)          5000000   \n",
      "                                                                 \n",
      " spatial_dropout1d_2 (Spati  (None, 250, 100)          0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 808       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5081208 (19.38 MB)\n",
      "Trainable params: 5081208 (19.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model.save_weights(\"models/multiclassComplaintClassifier.h5\")\n",
    "\n",
    "with open(\"models/tokenizerMulticlassComplaintClassification.pickle\", 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
