{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain.chains import LLMChain, LLMMathChain, SequentialChain, TransformChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain.tools import Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"api_key\")\n",
    "\n",
    "# Set the OpenAI API key as an environment variable\n",
    "os.environ['OPENAI_API_KEY'] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Defining utility functions for constructing a readable exchange\n",
    "\"\"\"\n",
    "\n",
    "def system_output(output):\n",
    "    \"\"\"Function for printing out to the user\"\"\"\n",
    "    print(\"======= Bot =======\")\n",
    "    print(output)\n",
    "\n",
    "\n",
    "def user_input():\n",
    "    \"\"\"Function for getting user input\"\"\"\n",
    "    print(\"======= Human Input =======\")\n",
    "    return input()\n",
    "\n",
    "\n",
    "def parsing_info(output):\n",
    "    \"\"\"Function for printing out key info\"\"\"\n",
    "    print(f\"*Info* {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Edge:\n",
    "\n",
    "    \"\"\"Edge\n",
    "    at its highest level, an edge checks if an input is good, then parses\n",
    "    data out of that input if it is good\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, condition, parse_prompt, parse_class, llm, max_retrys=3, out_node=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        condition (str): a True/False question about the input\n",
    "        parse_query (str): what the parser whould be extracting\n",
    "        parse_class (Pydantic BaseModel): the structure of the parse\n",
    "        llm (LangChain LLM): the large language model being used\n",
    "        \"\"\"\n",
    "        self.condition = condition\n",
    "        self.parse_prompt = parse_prompt\n",
    "        self.parse_class = parse_class\n",
    "        self.llm = llm\n",
    "\n",
    "        # how many times the edge has failed, for any reason, for deciding to skip\n",
    "        # when successful this resets to 0 for posterity.\n",
    "        self.num_fails = 0\n",
    "\n",
    "        # how many retrys are acceptable\n",
    "        self.max_retrys = max_retrys\n",
    "\n",
    "        # the node the edge directs towards\n",
    "        self.out_node = out_node\n",
    "\n",
    "    def check(self, input):\n",
    "        \"\"\"ask the llm if the input satisfies the condition\"\"\"\n",
    "        validation_query = f\"following the output schema, does the input satisfy the condition?\\ninput:{input}\\ncondition:{self.condition}\"\n",
    "\n",
    "        class Validation(BaseModel):\n",
    "            is_valid: bool = Field(description=\"if the condition is satisfied\")\n",
    "\n",
    "        parser = PydanticOutputParser(pydantic_object=Validation)\n",
    "        input = f\"Answer the user query.\\n{parser.get_format_instructions()}\\n{validation_query}\\n\"\n",
    "        return parser.parse(self.llm(input)).is_valid\n",
    "\n",
    "    def parse(self, input):\n",
    "        \"\"\"ask the llm to parse the parse_class, based on the parse_prompt, from the input\"\"\"\n",
    "        parse_query = f'{self.parse_prompt}:\\n\\n\"{input}\"'\n",
    "        parser = PydanticOutputParser(pydantic_object=self.parse_class)\n",
    "        input = f\"Answer the user query.\\n{parser.get_format_instructions()}\\n{parse_query}\\n\"\n",
    "        return parser.parse(self.llm(input))\n",
    "\n",
    "    def execute(self, input):\n",
    "        \"\"\"Executes the entire edge\n",
    "        returns a dictionary:\n",
    "        {\n",
    "            continue: bool,       weather or not should continue to next\n",
    "            result: parse_class,  the parsed result, if applicable\n",
    "            num_fails: int         the number of failed attempts\n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "        # input did't make it past the input condition for the edge\n",
    "        if not self.check(input):\n",
    "            self.num_fails += 1\n",
    "            if self.num_fails >= self.max_retrys:\n",
    "                return {\"continue\": True, \"result\": None, \"num_fails\": self.num_fails}\n",
    "            return {\"continue\": False, \"result\": None, \"num_fails\": self.num_fails}\n",
    "\n",
    "        try:\n",
    "            # attempting to parse\n",
    "            self.num_fails = 0\n",
    "            return {\n",
    "                \"continue\": True,\n",
    "                \"result\": self.parse(input),\n",
    "                \"num_fails\": self.num_fails,\n",
    "            }\n",
    "        except:\n",
    "            # there was some error in parsing.\n",
    "            # note, using the retry or correction parser here might be a good idea\n",
    "            self.num_fails += 1\n",
    "            if self.num_fails >= self.max_retrys:\n",
    "                return {\"continue\": True, \"result\": None, \"num_fails\": self.num_fails}\n",
    "            return {\"continue\": False, \"result\": None, \"num_fails\": self.num_fails}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the query for the condition, and parse prompt\n",
    "condition = \"Does the input contain fruits?\"\n",
    "parse_prompt = \"extract only the fruits from the following text. Do not extract any food items besides pure fruits.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model used in this test\n",
    "model_name = \"text-davinci-003\"\n",
    "temperature = 0.0\n",
    "model = OpenAI(model_name=model_name, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sampleOutputTemplate(BaseModel):\n",
    "    output: str = Field(description=\"contact information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the edge\n",
    "testEdge = Edge(\n",
    "    condition=condition,\n",
    "    parse_prompt=parse_prompt,\n",
    "    parse_class=sampleOutputTemplate,\n",
    "    llm=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = \"my favorite deserts are chocolate covered strawberries, oreos, bannana splits, and cake.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testEdge.check(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    \"\"\"Node\n",
    "    at its highest level, a node asks a user for some input, and trys\n",
    "    that input on all edges. It also manages and executes all\n",
    "    the edges it contains\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, prompt, retry_prompt):\n",
    "        \"\"\"\n",
    "        prompt (str): what to ask the user\n",
    "        retry_prompt (str): what to ask the user if all edges fail\n",
    "        parse_class (Pydantic BaseModel): the structure of the parse\n",
    "        llm (LangChain LLM): the large language model being used\n",
    "        \"\"\"\n",
    "\n",
    "        self.prompt = prompt\n",
    "        self.retry_prompt = retry_prompt\n",
    "        self.edges = []\n",
    "\n",
    "    def run_to_continue(self, _input):\n",
    "        \"\"\"Run all edges until one continues\n",
    "        returns the result of the continuing edge, or None\n",
    "        \"\"\"\n",
    "        for edge in self.edges:\n",
    "            res = edge.execute(_input)\n",
    "            if res[\"continue\"]:\n",
    "                return res\n",
    "        return None\n",
    "\n",
    "    def execute(self):\n",
    "        \"\"\"Handles the current conversational state\n",
    "        prompots the user, tries again, runs edges, etc.\n",
    "        returns the result from an adge\n",
    "        \"\"\"\n",
    "\n",
    "        # initial prompt for the conversational state\n",
    "        system_output(self.prompt)\n",
    "\n",
    "        while True:\n",
    "            # getting users input\n",
    "            _input = user_input()\n",
    "\n",
    "            # running through edges\n",
    "            res = self.run_to_continue(_input)\n",
    "\n",
    "            if res is not None:\n",
    "                # parse successful\n",
    "                parsing_info(f\"parse results: {res}\")\n",
    "                return res\n",
    "\n",
    "            # unsuccessful, prompting retry\n",
    "            system_output(self.retry_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining 2 edges from the node\n",
    "\n",
    "condition1 = \"Does the input contain a full and valid email?\"\n",
    "parse_prompt1 = \"extract the email from the following text.\"\n",
    "edge1 = Edge(condition1, parse_prompt1, sampleOutputTemplate, model)\n",
    "condition2 = (\n",
    "    \"Does the input contain a full and valid phone number (xxx-xxx-xxxx or xxxxxxxxxx)?\"\n",
    ")\n",
    "parse_prompt2 = \"extract the phone number from the following text.\"\n",
    "edge2 = Edge(condition2, parse_prompt2, sampleOutputTemplate, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining A Node\n",
    "test_node = Node(\n",
    "    prompt=\"Please input your full email address or phone number\",\n",
    "    retry_prompt=\"I'm sorry, I didn't understand your response.\\nPlease provide a full email address or phone number(in the format xxx-xxx-xxxx)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_node.edges = [edge1, edge2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Bot =======\n",
      "Please input your full email address or phone number\n",
      "======= Human Input =======\n"
     ]
    }
   ],
   "source": [
    "res = test_node.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.chat import *\n",
    "from data.graph import *\n",
    "from data.validation import PhoneCallTicket, UserProfile, PhoneCallRequest\n",
    "from graph.edge import *\n",
    "from graph.chain_based_node import *\n",
    "from graph.edge import BaseEdge\n",
    "from graph.node import BaseNode\n",
    "from graph.text_based_edge import PydanticTextBasedEdge\n",
    "from tools.rag_responder import HelpCenterAgent\n",
    "from tools.user_info_db import search_user_info_on_db, search_user_subscription_on_db\n",
    "from tools.audio_transcribe import call_customer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
